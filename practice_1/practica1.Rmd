---
title: "Initial Practice: Parkinson's Disease "
subtitle: "Statistical Learning with Deep Artificial Neural Networks"
author: "Alexander J Ohrt"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    number_sections: true
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    theme: readable
    highlight: textmate
    number_sections: true
editor_options: 
  chunk_output_type: console
urlcolor: blue
---

\tableofcontents
\newpage

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, warning = F, comment = "#>")
setwd("/home/ajo/gitRepos/DNN/practice_1")
library(dplyr)
library(keras)
```

# Introduction

We are working on a dataset describing Parkinson's disease. Click [here](https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring) for more information regarding the dataset. In short, the dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. 

The main objective is to predict the severity of Parkinson's disease based on the data. More details are given in the following. 

# Load the Parkinsons Data

```{r}
data <- read.csv("parkinsons_updrs.data")
str(data)
summary(data)
```

# Description of the Variables

As we have seen above, the dataset contains `r dim(data)[[1]]` rows, i.e. `r dim(data)[[1]]` measurements. The columns consist of **patient ID**, **age**, **sex**, **time interval since enrollment date**, **motor_UPDRS**, **total_UPDRS** and 16 voice biomedical measurements. The variables are the following

* subject. - The patient ID. Integer that uniquely identifies each subject.
* age - Age of each subject. 
* sex - Gender of the subject; '0' = male and '1' = female.
* test_time - Time since recruitment into the trial. The integer part is the number of days since recruitment.
* motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated.
* ctotal_UPDRS - Clinician's total UPDRS score, linearly interpolated.
* Jitter(%), Jitter(Abs), Jitter:RAP, Jitter:PPQ5, Jitter:DDP - Several measures of variation in fundamental frequency.
* Shimmer, Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, Shimmer:APQ11, Shimmer:DDA - Several measures of variation in amplitude.
* NHR, HNR - Two measures of ratio of noise to tonal components in the voice.
* RPDE - A nonlinear dynamical complexity measure.
* DFA - Signal fractal scaling exponent.
* PPE - A nonlinear measure of fundamental frequency variation.

As noted, the objective is to predict the severity of the disease, where severity is defined based on the variable **total_UPDRS**: The disease is severe if **total_UPDRS > 25**. This variable is created below. 

# Create the Binary Variable of Parkinson's Severity

```{r}
data$severity <- data$total_UPDRS > 25
dim(data)
summary(data$severity)
```

# Normalization

The variables of the 16 voice measurements are normalized by means of the min-max transformation.

```{r}
normalize <- function(x) {
    return((x- min(x))/(max(x)-min(x)))
}

for (i in 1:16){
  data[, 6+i] <- normalize(data[,6+i])
}

summary(data)
```

# Separation into Train and Test Data

I will use (pseudo-) random sampling to separate the data into a training and test set. 

```{r, results='hide'}
#set.seed(1)
ratio <- 0.7
sample.size <- floor(nrow(data) * ratio)
train.indices <- sample(1:nrow(data), size = sample.size)
train <- data[train.indices, ]
test <- data[-train.indices, ]

x_train <- data.matrix(train[,-23])
y_train <- to_categorical(train[, 23], num_classes = 2)
x_test <- data.matrix(test[,-23])
y_test <- to_categorical(test[, 23], num_classes = 2)
```


# Implementation of a Dense DNN

A dense deep neural network (DNN) for severity prediction is made. It has two hidden layers, with 10 nodes in each hidden layer. I have implemented two variants of this DNN; variant A has two output nodes, while variant B has only one output node. 

## Variant A: Two Output Nodes

Since we have two output nodes in this variant, we should use the *softmax* activation function in the output and the *categorical_crossentropy* loss function. 

```{r}
#set.seed(1)
# defining the model and layers
model <- keras_model_sequential() %>%
  layer_dense(units = 10, activation = 'relu', input_shape = c(ncol(x_train))) %>%
  layer_dense(units = 10, activation = 'relu') %>%
  layer_dense(units = ncol(y_train), activation = 'softmax')

summary(model)

# compile (define loss and optimizer)
model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))
# train (fit)
history <- model %>% fit(data.matrix(x_train), y_train, epochs = 50, 
              batch_size = 128, validation_split = 0.2)
# plot
plot(history)

# evaluate on training data. 
model %>% evaluate(x_train, y_train)
                   
# evaluate on test data. 
model %>% evaluate(x_test, y_test)
```

## Variant B: One Output Node

Since we have one output nodes in this variant, we should use the *sigmoid* activation function in the output and the *binary_crossentropy* loss function. 

```{r}
set.seed(1)
# defining the model and layers
model2 <- keras_model_sequential() %>%
  layer_dense(units = 10, activation = 'relu', input_shape = c(ncol(x_train))) %>%
  layer_dense(units = 10, activation = 'relu') %>%
  layer_dense(units = 1, activation = 'sigmoid')

summary(model2)

y_train2 <- as.numeric(data.matrix(train[,23]))
y_test2 <- as.numeric(data.matrix(test[,23]))

# compile (define loss and optimizer)
model2 %>% compile(loss = 'binary_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))
# train (fit)
history2 <- model2 %>% fit(data.matrix(x_train), y_train2, epochs = 50, 
              batch_size = 128, validation_split = 0.2)
# plot
plot(history2)

# evaluate on training data.
model2 %>% evaluate(x_train, y_train2)

# evaluate on testing data. 
model2 %>% evaluate(x_test, y_test2)
```

Note that the accuracy is reported as being higher for the test set compared to the training set in both variants (in many runs). This should not happen, but it looks like it does not happen when I do not min-max transform the data. Why? I have not been able to find an error, e.g. in the transform or in the test/train split. 

# Predictions 

## Predictions for Variant A

```{r}
y_pred <- model %>% predict(x_test) %>% k_argmax()
y_pred <- as.array(y_pred)
(tab <- table("Predictions" = y_pred, "Labels" = test[, 23]))

# accuracy in predictions (as shown with the "evaluate" above).
(tab[1]+tab[4])/sum(tab)
```

## Predictions for Variant B

```{r}
# Predictions for one output node 
y_pred2 <- model2 %>% predict(x_test) %>% `>`(0.5) %>% k_cast("int32")
y_pred2 <- as.array(y_pred2)
(tab2 <- table("Predictions" = y_pred2, "Labels" = test[, 23]))

# accuracy in predictions (as shown with the "evaluate" above).
(tab2[1]+tab2[4])/sum(tab2)
```
